{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Dependencies\n",
    "\n",
    "In this section, we import the necessary libraries and modules required for our analysis. These include:\n",
    "\n",
    "- `pandas` for data manipulation and analysis.\n",
    "- `numpy` for numerical operations.\n",
    "- `matplotlib.pyplot` for data visualization.\n",
    "- `seaborn` for statistical data visualization.\n",
    "- `sklearn` for machine learning algorithms and tools.\n",
    "\n",
    "By importing these dependencies, we ensure that we have all the tools needed to perform data analysis, visualization, and machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset and Checking for Missing Values\n",
    "\n",
    "In this section, we import the Iris dataset and perform an initial check for any missing values. Ensuring that there are no missing values is crucial for maintaining the integrity and quality of the data before proceeding with further analysis or modeling. The presence of missing values can significantly impact the results and performance of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données Iris\n",
    "df = pd.read_csv('iris.csv')\n",
    "df.info()\n",
    "df.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "# Affichage des 10 premières lignes du jeu de données\n",
    "print(df.head(10))\n",
    "\n",
    "# Vérification des valeurs manquantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Display\n",
    "\n",
    "In this section, we visualize the relationship between Sepal Length and Sepal Width for different species in the Iris dataset. The scatter plot below shows how these two features vary across the three species: Iris-setosa, Iris-versicolor, and Iris-virginica. This visualization helps in understanding the distribution and clustering of the species based on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='SepalLengthCm', y='SepalWidthCm', hue='Species')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.title('Sepal Length vs Sepal Width by Species')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='PetalLengthCm', y='PetalWidthCm', hue='Species')\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.title('Petal Length vs Petal Width by Species')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Histogram Visualization\n",
    "\n",
    "In this section, we will create histograms to visualize the distribution of different features in the Iris dataset. Histograms are useful for understanding the frequency distribution of numerical data and identifying patterns such as skewness, modality, and the presence of outliers.\n",
    "\n",
    "We will plot histograms for the following features:\n",
    "- Sepal Length\n",
    "- Sepal Width\n",
    "- Petal Length\n",
    "- Petal Width\n",
    "\n",
    "These visualizations will help us gain insights into the distribution of these features across the dataset.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12, 8), edgecolor='black', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Correlation Matrix\n",
    "\n",
    "In this section, we will examine the correlation matrix of the Iris dataset. The correlation matrix provides insights into the linear relationships between different features. A high positive correlation indicates that as one feature increases, the other feature tends to increase as well. Conversely, a high negative correlation indicates that as one feature increases, the other feature tends to decrease.\n",
    "\n",
    "The correlation matrix will help us understand the strength and direction of relationships between the features, which can be useful for feature selection and understanding the data's structure.\n",
    "\n",
    "Below is the correlation matrix for the Iris dataset:\n",
    "```\n",
    "\n",
    "```python\n",
    "print(corr)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Species', axis=1)\n",
    "y = df['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Model Training and Evaluation\n",
    "\n",
    "In this section, we train and evaluate various machine learning models on the Iris dataset. The models we will use include:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- K-Nearest Neighbors\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Support Vector Machine\n",
    "\n",
    "For each model, we will train it using the training set (`X_train`, `y_train`) and evaluate its performance on the test set (`X_test`, `y_test`). The performance metric we will use is accuracy, which measures the proportion of correctly classified instances.\n",
    "\n",
    "The results will help us understand which model performs best on this dataset and provide insights into the strengths and weaknesses of each algorithm.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Decision Tree\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Decision Tree Accuracy:', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Random Forest Accuracy:', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle K-Nearest Neighbors\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('K-Nearest Neighbors Accuracy:', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Logistic Regression Accuracy:', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Naive Bayes Accuracy:', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Support Vector Machine\n",
    "model = svm.SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Support Vector Machine Accuracy:', metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
